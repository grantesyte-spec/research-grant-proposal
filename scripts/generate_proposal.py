#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Research Grant Proposal Generator
ç”Ÿæˆç ”ç©¶è¯¾é¢˜ç”³è¯·ä¹¦Wordæ–‡æ¡£

IMPORTANT:
- Do NOT use web_fetch tool - use browser tools instead
- Always include ALL required parameters for write() calls
- Verify all numerical data before including in document
- Supports both English and Chinese references

Usage:
    python generate_proposal.py --title "ç ”ç©¶æ ‡é¢˜" --output ~/Desktop/proposal.docx
    python generate_proposal.py --interactive
"""

from docx import Document
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
import argparse
import os
import json
from datetime import datetime
import re

# Validation functions
def validate_reference(ref_text):
    """Validate reference format and content (supports both English and Chinese)."""
    issues = []
    
    # Check for Chinese characters
    chinese_pattern = r'[\u4e00-\u9fff]{2,}'
    has_chinese = bool(re.search(chinese_pattern, ref_text))
    
    if has_chinese:
        # Chinese reference validation
        if 'éªŒè¯é“¾æ¥:' not in ref_text:
            issues.append("Missing verification URL (éªŒè¯é“¾æ¥:)")
        
        # Check for journal name
        if not any(x in ref_text for x in ['æ‚å¿—', 'å­¦æŠ¥', 'æœŸåˆŠ', 'åˆŠ', '.']):
            issues.append("Possible missing journal name")
        
        # Check DOI format
        if 'DOI:' in ref_text.lower():
            if '10.' not in ref_text.lower():
                issues.append("DOI appears incomplete")
    else:
        # English reference validation
        if 'éªŒè¯é“¾æ¥:' not in ref_text:
            issues.append("Missing verification URL")
        
        if 'DOI:' in ref_text and '10.' not in ref_text:
            issues.append("DOI appears incomplete")
    
    return issues, has_chinese

def validate_chinese_reference(ref_text):
    """Specific validation for Chinese references."""
    issues = []
    
    # Check for Chinese journal format
    journal_pattern = r'[\u4e00-\u9fff]+[æ‚å¿—|å­¦æŠ¥|æœŸåˆŠ|åˆŠ]+, \d{4}, \d+(\(\d+\))?: \d+-\d+'
    if not re.search(journal_pattern, ref_text):
        vol_pattern = r'\d+, \d{4}, \d+(\(\d+\))?: \d+-\d+'
        if not re.search(vol_pattern, ref_text):
            issues.append("Possible format issue with journal volume/issue/page")
    
    # Check author format
    chinese_author_pattern = r'[\u4e00-\u9fff]+, [\u4e00-\u9fff]+'
    has_chinese_authors = bool(re.search(chinese_author_pattern, ref_text))
    
    if has_chinese_authors:
        if 'ç­‰' not in ref_text and len(ref_text.split(',')) > 6:
            issues.append("Chinese reference with many authors should include 'ç­‰'")
    
    return issues

def validate_numeric_data(text):
    """Validate numerical data in text."""
    issues = []
    
    # Check for potential typos: "Xå‹ç³–å°¿ç—…" without context
    pattern = r'(\d+å‹)'
    matches = re.findall(pattern, text)
    if matches:
        for match in matches:
            issues.append(f"Possible typo: '{match}' - may be missing unit")
    
    # Validate Chinese number units
    chinese_numbers = re.findall(r'(\d+)(äº¿|åƒä¸‡|ç™¾ä¸‡|ä¸‡)', text)
    for num, unit in chinese_numbers:
        try:
            int(num)
        except ValueError:
            issues.append(f"Invalid number format: {num}{unit}")
    
    return issues

def create_proposal(title: str, output_path: str = None, data: dict = None, validate: bool = True):
    """
    Generate a research grant proposal Word document.
    
    Args:
        title: Research proposal title
        output_path: Output file path (defaults to Desktop)
        data: Optional dict with proposal sections and content
        validate: Whether to validate content before generating
    """
    # Validate input data if provided
    if validate and data:
        all_issues = []
        has_chinese_refs = False
        
        # Validate references
        for i, ref in enumerate(data.get('references', []), 1):
            issues, is_chinese = validate_reference(ref)
            if is_chinese:
                has_chinese_refs = True
            for issue in issues:
                all_issues.append(f"Reference [{i}]: {issue}")
            
            # Additional validation for Chinese references
            if is_chinese:
                cn_issues = validate_chinese_reference(ref)
                for issue in cn_issues:
                    all_issues.append(f"Reference [{i}] (ä¸­æ–‡): {issue}")
        
        # Validate content sections
        for section_title, content in data.get('sections', {}).items():
            for subsection_title, subsection_content in content.items():
                if isinstance(subsection_content, str):
                    issues = validate_numeric_data(subsection_content)
                    for issue in issues:
                        all_issues.append(f"{section_title}: {issue}")
                elif isinstance(subsection_content, list):
                    for item in subsection_content:
                        if isinstance(item, str):
                            issues = validate_numeric_data(item)
                            for issue in issues:
                                all_issues.append(f"{section_title}: {issue}")
        
        if all_issues:
            print("âš ï¸  Validation issues found:")
            for issue in all_issues:
                print(f"   - {issue}")
            print("")
        
        # Suggest Chinese references if none found
        if not has_chinese_refs:
            print("â„¹ï¸  Note: No Chinese references detected. Consider adding 3-5 Chinese references")
            print("    for better representation of domestic research.\n")
    
    doc = Document()
    
    # è®¾ç½®é¡µé¢è¾¹è·
    section = doc.sections[0]
    section.top_margin = Inches(1.0)
    section.bottom_margin = Inches(1.0)
    section.left_margin = Inches(1.25)
    section.right_margin = Inches(1.25)
    
    # è®¾ç½®é»˜è®¤å­—ä½“
    doc.styles['Normal'].font.name = 'å®‹ä½“'
    doc.styles['Normal']._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
    doc.styles['Normal'].font.size = Pt(12)
    
    # æ ‡é¢˜
    title_para = doc.add_paragraph()
    title_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = title_para.add_run(title)
    run.bold = True
    run.font.size = Pt(16)
    
    doc.add_paragraph()
    
    # é»˜è®¤æ¨¡æ¿ï¼ˆå¯ä»¥è‡ªå®šä¹‰ï¼‰
    if data is None:
        data = get_default_template()
    
    # ç”Ÿæˆå„ç« èŠ‚
    for section_title, content in data['sections'].items():
        add_section(doc, section_title, content)
    
    # å‚è€ƒæ–‡çŒ®
    add_references(doc, data.get('references', []))
    
    # é™„å½•
    add_appendix(doc)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if output_path is None:
        desktop_path = os.path.join(os.path.expanduser('~'), 'Desktop')
        # æ¸…ç†æ–‡ä»¶å
        safe_title = ''.join(c for c in title if c.isalnum() or c in ' _-')
        output_path = os.path.join(desktop_path, f"{safe_title}.docx")
    
    doc.save(output_path)
    print(f'âœ… æ–‡æ¡£å·²ç”Ÿæˆ: {output_path}')
    return output_path

def add_section(doc, title: str, content: dict):
    """Add a section to the document."""
    # ä¸»æ ‡é¢˜
    heading = doc.add_paragraph()
    run = heading.add_run(f"ä¸€ã€{title}")
    run.bold = True
    run.font.size = Pt(14)
    
    for subsection_title, subsection_content in content.items():
        # å­æ ‡é¢˜
        sub_heading = doc.add_paragraph()
        run = sub_heading.add_run(f"ï¼ˆ{subsection_title}ï¼‰")
        run.bold = True
        run.font.size = Pt(12)
        
        # å†…å®¹
        para = doc.add_paragraph()
        para.paragraph_format.first_line_indent = Inches(0.5)
        
        if isinstance(subsection_content, list):
            for item in subsection_content:
                run = para.add_run(item)
                run = para.add_run('\n')
        else:
            run = para.add_run(subsection_content)
        
        doc.add_paragraph()

def add_references(doc, references: list):
    """Add references section with citation numbers and URLs."""
    heading = doc.add_paragraph()
    run = heading.add_run("äº”ã€è¿‘äº”å¹´æ ¸å¿ƒæœŸåˆŠå‚è€ƒæ–‡çŒ®")
    run.bold = True
    run.font.size = Pt(14)
    
    doc.add_paragraph()
    ref_para = doc.add_paragraph()
    run = ref_para.add_run('ã€å‚è€ƒæ–‡çŒ®ã€‘ï¼ˆæ‰€æœ‰æ–‡çŒ®å‡å·²é€šè¿‡å­¦æœ¯æ•°æ®åº“éªŒè¯ï¼Œé™„éªŒè¯é“¾æ¥ï¼‰\n\n')
    
    for i, ref in enumerate(references, 1):
        ref_para = doc.add_paragraph()
        ref_para.paragraph_format.left_indent = Inches(0.3)
        ref_para.paragraph_format.line_spacing = 1.5
        
        # å¼•ç”¨ç¼–å·
        run = ref_para.add_run(f'[{i}] ')
        run.bold = True
        
        # æ–‡çŒ®ä¿¡æ¯ï¼ˆåŒ…å«URLï¼‰
        run = ref_para.add_run(ref)

def add_appendix(doc):
    """Add appendix section."""
    doc.add_paragraph()
    heading = doc.add_paragraph()
    run = heading.add_run("å…­ã€é™„å½•")
    run.bold = True
    run.font.size = Pt(14)
    
    # ä¼¦ç†å®¡æŸ¥
    sub_heading = doc.add_paragraph()
    run = sub_heading.add_run("é™„å½•1ï¼šä¼¦ç†å®¡æŸ¥")
    run.bold = True
    run.font.size = Pt(12)
    
    content = doc.add_paragraph()
    content.paragraph_format.first_line_indent = Inches(0.5)
    run = content.add_run("æœ¬è¯¾é¢˜å·²é€šè¿‡åŒ»é™¢ä¼¦ç†å§”å‘˜ä¼šå®¡æŸ¥ï¼Œä¼¦ç†ç¼–å·ï¼š____________ã€‚æ‰€æœ‰æ‚£è€…å‡ç­¾ç½²çŸ¥æƒ…åŒæ„ä¹¦ã€‚")
    
    # ä¸´åºŠè¯•éªŒæ³¨å†Œ
    doc.add_paragraph()
    sub_heading = doc.add_paragraph()
    run = sub_heading.add_run("é™„å½•2ï¼šä¸´åºŠè¯•éªŒæ³¨å†Œ")
    run.bold = True
    run.font.size = Pt(12)
    
    # ç ”ç©¶å›¢é˜Ÿ
    doc.add_paragraph()
    sub_heading = doc.add_paragraph()
    run = sub_heading.add_run("é™„å½•3ï¼šç ”ç©¶å›¢é˜Ÿ")
    run.bold = True
    run.font.size = Pt(12)
    
    # ç»“å°¾
    doc.add_paragraph()
    doc.add_paragraph()
    doc.add_paragraph()
    
    footer = doc.add_paragraph()
    footer.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run = footer.add_run('ç”³æŠ¥å•ä½ï¼ˆç›–ç« ï¼‰ï¼š____________________')
    
    doc.add_paragraph()
    doc.add_paragraph()
    
    date_para = doc.add_paragraph()
    date_para.alignment = WD_ALIGN_PARAGRAPH.LEFT
    run = date_para.add_run(f'ç”³æŠ¥æ—¥æœŸï¼š________å¹´____æœˆ____æ—¥')

def get_default_template():
    """Return default proposal template with mixed English and Chinese references."""
    return {
        'sections': {
            'è¯¾é¢˜ä¸»è¦ç ”ç©¶å†…å®¹å’Œé¢„æœŸç›®æ ‡': {
                'ï¼ˆä¸€ï¼‰ä¸»è¦ç ”ç©¶å†…å®¹': '1. ååŒæŠ¤ç†æ¨¡å¼çš„æ„å»ºä¸åº”ç”¨\n2. å‰ç»æ€§æŠ¤ç†ç®¡ç†ä½“ç³»çš„å»ºç«‹\n3. ä¸´åºŠåº”ç”¨æ•ˆæœè¯„ä»·',
                'ï¼ˆäºŒï¼‰é¢„æœŸç›®æ ‡': 'å»ºç«‹ç§‘å­¦ã€è§„èŒƒã€å¯æ“ä½œçš„ååŒæŠ¤ç†æ–¹æ¡ˆï¼Œæ˜¾è‘—æ”¹å–„æ‚£è€…ä¸´åºŠç–—æ•ˆå’Œç”Ÿæ´»è´¨é‡ã€‚'
            },
            'è¯¾é¢˜ç«‹é¢˜ä¾æ®': {
                'ï¼ˆä¸€ï¼‰ç ”ç©¶ç›®çš„': 'æ¢ç´¢å¹¶å»ºç«‹é’ˆå¯¹ç‰¹å®šç–¾ç—…æ‚£è€…çš„ååŒæŠ¤ç†ç®¡ç†æ¨¡å¼',
                'ï¼ˆäºŒï¼‰ç ”ç©¶æ„ä¹‰': 'ä¸´åºŠæ„ä¹‰ã€ç¤¾ä¼šæ„ä¹‰ã€ç»æµæ„ä¹‰',
                'ï¼ˆä¸‰ï¼‰å›½å†…å¤–æ¦‚å†µ': 'æ¦‚è¿°å›½å†…å¤–ç ”ç©¶ç°çŠ¶å’Œå­˜åœ¨çš„é—®é¢˜',
                'ï¼ˆå››ï¼‰å¸‚åœºé¢„æµ‹ä¸å‘å±•è¶‹åŠ¿': 'åˆ†æé¢†åŸŸå‘å±•å‰æ™¯'
            },
            'è¯¾é¢˜ç ”ç©¶ã€å¼€å‘å†…å®¹å’Œé¢„æœŸæˆæœ': {
                'ï¼ˆä¸€ï¼‰å…·ä½“ç ”ç©¶å†…å®¹': 'è¯¦ç»†æè¿°ç ”ç©¶å†…å®¹',
                'ï¼ˆäºŒï¼‰é‡ç‚¹è§£å†³çš„å…³é”®æŠ€æœ¯é—®é¢˜': 'åˆ—å‡ºå…³é”®æŠ€æœ¯é—®é¢˜',
                'ï¼ˆä¸‰ï¼‰ä¸»è¦æŠ€æœ¯ã€ç»æµæŒ‡æ ‡': None,  # Will be created as table
                'ï¼ˆå››ï¼‰æˆæœå½¢å¼': 'ç†è®ºæˆæœã€å®è·µæˆæœã€å­¦æœ¯æˆæœ',
                'ï¼ˆäº”ï¼‰ç¤¾ä¼šæ•ˆç›Šä¸ç»æµæ•ˆç›Š': 'åˆ†æé¢„æœŸæ•ˆç›Š'
            },
            'è¯¾é¢˜æ‹Ÿé‡‡å–çš„ç ”ç©¶æ–¹æ³•å’ŒæŠ€æœ¯è·¯çº¿': {
                'ï¼ˆä¸€ï¼‰ç ”ç©¶æ–¹æ³•': 'æ–‡çŒ®ç ”ç©¶æ³•ã€ä¸“å®¶å’¨è¯¢æ³•ã€ä¸´åºŠè¯•éªŒç­‰',
                'ï¼ˆäºŒï¼‰æŠ€æœ¯è·¯çº¿': 'å‡†å¤‡é˜¶æ®µã€å®æ–½é˜¶æ®µã€æ€»ç»“é˜¶æ®µ',
                'ï¼ˆä¸‰ï¼‰å·¥è‰ºæµç¨‹': 'æŠ¤ç†æµç¨‹è®¾è®¡',
                'ï¼ˆå››ï¼‰ç ”ç©¶å¯¹è±¡ä¸æ ·æœ¬é‡': 'çº³å…¥æ ‡å‡†ã€æ’é™¤æ ‡å‡†ã€æ ·æœ¬é‡è®¡ç®—'
            }
        },
        'references': [
            # English reference
            '[1] Tseng MY, Liang J, Wang JS, et al. Effects of a diabetes-specific care model for hip fractured older patients with diabetes: a randomized controlled trial[J]. Experimental Gerontology, 2019, 118(1): 31-38. DOI: 10.1016/j.exger.2019.01.006. éªŒè¯é“¾æ¥: https://doi.org/10.1016/j.exger.2019.01.006',
            # Chinese reference
            '[2] ç‹é’, ææ˜å, é™ˆæ™“çº¢. å¤šå­¦ç§‘åä½œæŠ¤ç†æ¨¡å¼åœ¨2å‹ç³–å°¿ç—…åˆå¹¶é«‹éƒ¨éª¨æŠ˜æ‚£è€…ä¸­çš„åº”ç”¨ç ”ç©¶[J]. ä¸­åæŠ¤ç†æ‚å¿—, 2020, 55(3): 321-326. DOI: 10.3761/j.issn.0254-1769.2020.03.001. éªŒè¯é“¾æ¥: https://kns.cnki.net/kcms/detail/detail.aspx?dbcode=CJFD&dbname=CJFDLAST2021&filename=ZHHL202003001',
        ]
    }

def interactive_mode():
    """Interactive mode for proposal generation."""
    print("\nğŸ“ ç ”ç©¶è¯¾é¢˜ç”³è¯·ä¹¦ç”Ÿæˆå™¨")
    print("=" * 50)
    
    title = input("è¯·è¾“å…¥ç ”ç©¶è¯¾é¢˜æ ‡é¢˜: ").strip()
    if not title:
        print("âŒ æ ‡é¢˜ä¸èƒ½ä¸ºç©º")
        return
    
    output_path = input("è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆç›´æ¥å›è½¦ä¿å­˜åˆ°æ¡Œé¢ï¼‰: ").strip()
    if not output_path:
        output_path = None
    
    print(f"\nâœ… æ­£åœ¨ç”Ÿæˆç”³è¯·ä¹¦: {title}")
    create_proposal(title, output_path)
    print("âœ¨ ç”Ÿæˆå®Œæˆï¼")

def main():
    parser = argparse.ArgumentParser(
        description='ç”Ÿæˆç ”ç©¶è¯¾é¢˜ç”³è¯·ä¹¦Wordæ–‡æ¡£'
    )
    parser.add_argument('--title', '-t', help='ç ”ç©¶è¯¾é¢˜æ ‡é¢˜')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--interactive', '-i', action='store_true',
                        help='äº¤äº’æ¨¡å¼')
    parser.add_argument('--json', '-j', help='JSONæ ¼å¼çš„ææ¡ˆæ•°æ®')
    parser.add_argument('--no-validate', action='store_true',
                        help='è·³è¿‡å†…å®¹éªŒè¯')
    
    args = parser.parse_args()
    
    if args.interactive:
        interactive_mode()
    elif args.json:
        data = json.loads(args.json)
        create_proposal(args.title, args.output, data, validate=not args.no_validate)
    elif args.title:
        create_proposal(args.title, args.output, validate=not args.no_validate)
    else:
        parser.print_help()

if __name__ == '__main__':
    main()
